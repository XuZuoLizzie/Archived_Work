{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XuZuoLizzie/Archived_Work/blob/main/Generating_PubMed_Abstracts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94apYD5COmNh"
      },
      "source": [
        "# Generating PubMed abstracts"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this homework is to train a character-level RNN to generate PubMed abstracts. The trained model is able to generate PubMed abstracts in Medline format."
      ],
      "metadata": {
        "id": "kB-2dPiqENj6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttkxOvWAOtSs"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NiJiT7fbFos",
        "outputId": "852746fd-ebe8-4ce5-ec19-486e115d106e"
      },
      "source": [
        "! pip install biopython"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67bxxaMmccBA"
      },
      "source": [
        "class Record():\n",
        "  def __init__(self, pmid, title, abstract):\n",
        "    self.pmid = pmid\n",
        "    self.title = title\n",
        "    self.abstract = abstract"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QCnNRIobT2M",
        "outputId": "f14b2ad7-4a46-44bf-b854-988e18dd309b"
      },
      "source": [
        "from Bio import Medline\n",
        "\n",
        "fp = \"/content/medline.0.txt\"\n",
        "\n",
        "records = []\n",
        "with open(fp) as handle:\n",
        "  for article in Medline.parse(handle):\n",
        "    records.append(Record(article['PMID'], article['TI'], article['AB']))\n",
        "\n",
        "print(records[0].pmid, records[0].title, records[0].abstract)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22997744 [Value of magnetic resonance imaging in the diagnosis of recurrent colorectal cancer]. To diagnose recurrent colorectal cancer is an urgent problem of oncoproctology. Eighty patients with suspected recurrent colon tumor were examined. All the patients underwent irrigoscopy, colonoscopy, magnetic resonance imaging of the abdomen and small pelvis. The major magnetic resonance symptoms of recurrent colon tumors were studied; a differential diagnosis of recurrent processes and postoperative changes at the site of intervention was made.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-cgYI61sRSi"
      },
      "source": [
        "# abstracts = [record.abstract for record in records]\n",
        "abstracts = []\n",
        "for record in records:\n",
        "  content = \"PMID - \" + record.pmid + \"\\n\" + \"AB - \" + record.abstract\n",
        "  abstracts.append(content)\n",
        "\n",
        "input = \"\\n\\n\".join(abstracts)\n",
        "\n",
        "with open(\"/content/medline_input.txt\", 'w', encoding='ascii') as input_file:\n",
        "  input_file.write(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R_GPE0yRvSl"
      },
      "source": [
        "## Train the RNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvzLyDhAr3EJ",
        "outputId": "e3a9d553-5d61-41cf-9b50-234dec9c4cdd"
      },
      "source": [
        "! git clone https://github.com/spro/char-rnn.pytorch.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'char-rnn.pytorch'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "Unpacking objects: 100% (54/54), done.\n",
            "remote: Total 54 (delta 0), reused 0 (delta 0), pack-reused 54\u001b[K\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDWwESUWr_PQ",
        "outputId": "813633e4-3ee5-49ff-c364-95dbb93d1ed4"
      },
      "source": [
        "% cd char-rnn.pytorch/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/char-rnn.pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IRUTPx_vF0h",
        "outputId": "fd901c6c-9617-49ed-be6e-b1b8a04afb42"
      },
      "source": [
        "! ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 24\n",
            "-rwxr-xr-x 1 root root 1784 Oct 18 20:14 generate.py\n",
            "-rw-r--r-- 1 root root  756 Oct 18 20:14 helpers.py\n",
            "-rw-r--r-- 1 root root 1081 Oct 18 20:14 LICENSE\n",
            "-rw-r--r-- 1 root root 1617 Oct 18 20:14 model.py\n",
            "-rw-r--r-- 1 root root 1950 Oct 18 20:14 README.md\n",
            "-rwxr-xr-x 1 root root 3160 Oct 18 20:14 train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8d7KoCEwo-l",
        "outputId": "9eb5eb62-0ae7-459a-a9cd-8a0f05cae56e"
      },
      "source": [
        "! pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 30 kB 8.1 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 61 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 81 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 112 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 122 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 133 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 143 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 153 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 163 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 174 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 184 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 194 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 204 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 215 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 225 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235 kB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPXEeu8lyORo",
        "outputId": "9fc93703-12ee-4064-cf26-dcd9212c316d"
      },
      "source": [
        "%%writefile train.py\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# https://github.com/spro/char-rnn.pytorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from helpers import *\n",
        "from model import *\n",
        "from generate import *\n",
        "\n",
        "# Parse command line arguments\n",
        "argparser = argparse.ArgumentParser()\n",
        "argparser.add_argument('filename', type=str)\n",
        "argparser.add_argument('--model', type=str, default=\"gru\")\n",
        "argparser.add_argument('--n_epochs', type=int, default=2000)\n",
        "argparser.add_argument('--print_every', type=int, default=100)\n",
        "argparser.add_argument('--hidden_size', type=int, default=100)\n",
        "argparser.add_argument('--n_layers', type=int, default=2)\n",
        "argparser.add_argument('--learning_rate', type=float, default=0.01)\n",
        "argparser.add_argument('--chunk_len', type=int, default=200)\n",
        "argparser.add_argument('--batch_size', type=int, default=100)\n",
        "argparser.add_argument('--shuffle', action='store_true')\n",
        "argparser.add_argument('--cuda', action='store_true')\n",
        "args = argparser.parse_args()\n",
        "\n",
        "if args.cuda:\n",
        "    print(\"Using CUDA\")\n",
        "\n",
        "file, file_len = read_file(args.filename)\n",
        "\n",
        "def random_training_set(chunk_len, batch_size):\n",
        "    inp = torch.LongTensor(batch_size, chunk_len)\n",
        "    target = torch.LongTensor(batch_size, chunk_len)\n",
        "    for bi in range(batch_size):\n",
        "        start_index = random.randint(0, file_len - chunk_len)\n",
        "        end_index = start_index + chunk_len + 1\n",
        "        chunk = file[start_index:end_index]\n",
        "        inp[bi] = char_tensor(chunk[:-1])\n",
        "        target[bi] = char_tensor(chunk[1:])\n",
        "    inp = Variable(inp)\n",
        "    target = Variable(target)\n",
        "    if args.cuda:\n",
        "        inp = inp.cuda()\n",
        "        target = target.cuda()\n",
        "    return inp, target\n",
        "\n",
        "def train(inp, target):\n",
        "    hidden = decoder.init_hidden(args.batch_size)\n",
        "    # if args.cuda:\n",
        "    #     hidden = hidden.cuda()\n",
        "    if args.cuda:\n",
        "        if args.model == \"gru\":\n",
        "            hidden = hidden.cuda()\n",
        "        else:\n",
        "            hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
        "    decoder.zero_grad()\n",
        "    loss = 0\n",
        "\n",
        "    for c in range(args.chunk_len):\n",
        "        output, hidden = decoder(inp[:,c], hidden)\n",
        "        loss += criterion(output.view(args.batch_size, -1), target[:,c])\n",
        "\n",
        "    loss.backward()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    # return loss.data[0] / args.chunk_len\n",
        "    return loss.data / args.chunk_len\n",
        "\n",
        "def save():\n",
        "    save_filename = os.path.splitext(os.path.basename(args.filename))[0] + '.pt'\n",
        "    torch.save(decoder, save_filename)\n",
        "    print('Saved as %s' % save_filename)\n",
        "\n",
        "# Initialize models and start training\n",
        "\n",
        "decoder = CharRNN(\n",
        "    n_characters,\n",
        "    args.hidden_size,\n",
        "    n_characters,\n",
        "    model=args.model,\n",
        "    n_layers=args.n_layers,\n",
        ")\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=args.learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if args.cuda:\n",
        "    decoder.cuda()\n",
        "\n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0\n",
        "\n",
        "try:\n",
        "    print(\"Training for %d epochs...\" % args.n_epochs)\n",
        "    for epoch in tqdm(range(1, args.n_epochs + 1)):\n",
        "        loss = train(*random_training_set(args.chunk_len, args.batch_size))\n",
        "        loss_avg += loss\n",
        "\n",
        "        if epoch % args.print_every == 0:\n",
        "            print('[%s (%d %d%%) %.4f]' % (time_since(start), epoch, epoch / args.n_epochs * 100, loss))\n",
        "            print(generate(decoder, 'Wh', 100, cuda=args.cuda), '\\n')\n",
        "\n",
        "    print(\"Saving...\")\n",
        "    save()\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Saving before quit...\")\n",
        "    save()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHfepFnhmHnF",
        "outputId": "66c28f1d-1c70-41ed-a1cb-f06818ff15cf"
      },
      "source": [
        "%%writefile generate.py\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# https://github.com/spro/char-rnn.pytorch\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "from helpers import *\n",
        "from model import *\n",
        "\n",
        "def generate(decoder, prime_str='A', predict_len=100, temperature=0.8, cuda=False):\n",
        "    hidden = decoder.init_hidden(1)\n",
        "    prime_input = Variable(char_tensor(prime_str).unsqueeze(0))\n",
        "\n",
        "    if cuda:\n",
        "        if isinstance(hidden, tuple):\n",
        "            hidden = (hidden[0].cuda(), hidden[1].cuda())\n",
        "        else:\n",
        "            hidden = hidden.cuda()\n",
        "        prime_input = prime_input.cuda()\n",
        "    predicted = prime_str\n",
        "\n",
        "    # Use priming string to \"build up\" hidden state\n",
        "    for p in range(len(prime_str) - 1):\n",
        "        _, hidden = decoder(prime_input[:,p], hidden)\n",
        "\n",
        "    inp = prime_input[:,-1]\n",
        "\n",
        "    for p in range(predict_len):\n",
        "        output, hidden = decoder(inp, hidden)\n",
        "\n",
        "        # Sample from the network as a multinomial distribution\n",
        "        output_dist = output.data.view(-1).div(temperature).exp()\n",
        "        top_i = torch.multinomial(output_dist, 1)[0]\n",
        "\n",
        "        # Add predicted character to string and use as next input\n",
        "        predicted_char = all_characters[top_i]\n",
        "        predicted += predicted_char\n",
        "        inp = Variable(char_tensor(predicted_char).unsqueeze(0))\n",
        "        if cuda:\n",
        "            inp = inp.cuda()\n",
        "\n",
        "    return predicted\n",
        "\n",
        "# Run as standalone script\n",
        "if __name__ == '__main__':\n",
        "\n",
        "# Parse command line arguments\n",
        "    argparser = argparse.ArgumentParser()\n",
        "    argparser.add_argument('filename', type=str)\n",
        "    argparser.add_argument('-p', '--prime_str', type=str, default='A')\n",
        "    argparser.add_argument('-l', '--predict_len', type=int, default=100)\n",
        "    argparser.add_argument('-t', '--temperature', type=float, default=0.8)\n",
        "    argparser.add_argument('--cuda', action='store_true')\n",
        "    args = argparser.parse_args()\n",
        "\n",
        "    decoder = torch.load(args.filename)\n",
        "    del args.filename\n",
        "    print(generate(decoder, **vars(args)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting generate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNCKQdScuwan",
        "outputId": "023a493a-77b4-42d7-fa7e-2873a3963a84"
      },
      "source": [
        "! python train.py /content/medline_input.txt \\\n",
        "--model lstm \\\n",
        "--n_epochs 2000 \\\n",
        "--print_every 100 \\\n",
        "--learning_rate 0.01 \\\n",
        "--batch_size 100 \\\n",
        "--cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using CUDA\n",
            "Training for 2000 epochs...\n",
            "  5% 99/2000 [00:49<15:56,  1.99it/s][0m 49s (100 5%) 1.8705]\n",
            "Whition in the 6.879 nospatial dissaibker, ound prenionalles restations were with regressiectiated the \n",
            "\n",
            " 10% 199/2000 [01:38<14:50,  2.02it/s][1m 39s (200 10%) 1.5181]\n",
            "Whome in 5 time and reate that the formatient depin cases. studies the gastric cancer in the case, and \n",
            "\n",
            " 15% 299/2000 [02:28<13:59,  2.03it/s][2m 29s (300 15%) 1.4106]\n",
            "Whogeneges and the patients with women with to despited the endostanced with the levels carcinominal c \n",
            "\n",
            " 20% 399/2000 [03:18<13:25,  1.99it/s][3m 18s (400 20%) 1.3475]\n",
            "Whe prostate and gene additiorations, malignancy with a single sage eye of metastatic associated to be \n",
            "\n",
            " 25% 499/2000 [04:07<12:17,  2.03it/s][4m 8s (500 25%) 1.2893]\n",
            "Whology (CD32) (CRC) proscopy.\n",
            "\n",
            "PMID - 23006454\n",
            "AB - Curring neoplasion-chronit cancer potential were  \n",
            "\n",
            " 30% 599/2000 [04:57<11:38,  2.01it/s][4m 57s (600 30%) 1.3078]\n",
            "Whis provide DSS4 in HDAT axmation in pathways determining (including, interventional progression was  \n",
            "\n",
            " 35% 699/2000 [05:47<10:47,  2.01it/s][5m 47s (700 35%) 1.2652]\n",
            "Wh-targetation and may a levels for include the recent the preation in the performolated resulting bet \n",
            "\n",
            " 40% 799/2000 [06:36<09:49,  2.04it/s][6m 37s (800 40%) 1.2477]\n",
            "Whe cohort bleing cell cancer was reactivation (x) and colorectal cancer increasing the risk of the li \n",
            "\n",
            " 45% 899/2000 [07:26<09:08,  2.01it/s][7m 26s (900 45%) 1.2333]\n",
            "Whose contrast Snexach 1.6 men those in the negative P = 0.007). The pro-existing for their cancer was \n",
            "\n",
            " 50% 999/2000 [08:15<08:11,  2.04it/s][8m 16s (1000 50%) 1.2665]\n",
            "Whe costs, causall studied by present prostate cancer. The interventions of cell directly approach to  \n",
            "\n",
            " 55% 1099/2000 [09:05<07:32,  1.99it/s][9m 5s (1100 55%) 1.2025]\n",
            "Whe poor cycles, the ability of interaction completely and selents all death is convenal propose of bB \n",
            "\n",
            " 60% 1199/2000 [09:55<06:35,  2.03it/s][9m 55s (1200 60%) 1.2064]\n",
            "When anti-cancer daily and systemic approach findings in patient procedures in and sexual assafeloprog \n",
            "\n",
            " 65% 1299/2000 [10:45<05:49,  2.01it/s][10m 45s (1300 65%) 1.1604]\n",
            "Whilets was disease. A co-existing and immunohistochemist diaperative relation that the development ec \n",
            "\n",
            " 70% 1399/2000 [11:34<04:57,  2.02it/s][11m 35s (1400 70%) 1.1834]\n",
            "Whit outcome in gastric cancer (TCA and 18), and the mice and for a survival and derived in the metace \n",
            "\n",
            " 75% 1499/2000 [12:24<04:08,  2.01it/s][12m 24s (1500 75%) 1.1819]\n",
            "Whe total of this disease resection with provide the first treat specific combination that inhibitors  \n",
            "\n",
            " 80% 1599/2000 [13:13<03:20,  2.00it/s][13m 13s (1600 80%) 1.1679]\n",
            "Whit noding the most derivatively assay was means are reconstituted to defininetics in the TRAIL resis \n",
            "\n",
            " 85% 1699/2000 [14:02<02:27,  2.03it/s][14m 3s (1700 85%) 1.1482]\n",
            "Whose with have been for CD14(+), VEC expression to regulatory prostate cancer pathway studies of canc \n",
            "\n",
            " 90% 1799/2000 [14:52<01:39,  2.02it/s][14m 52s (1800 90%) 1.1485]\n",
            "Whit clinical value multivariate complex groups. By nodes, while for the increase in review the blight \n",
            "\n",
            " 95% 1899/2000 [15:41<00:50,  1.99it/s][15m 42s (1900 95%) 1.1678]\n",
            "What laryng combined to anal characteristics and clinical staging regarding evaluated 1-DM (mist, deat \n",
            "\n",
            "100% 1999/2000 [16:31<00:00,  2.04it/s][16m 31s (2000 100%) 1.1479]\n",
            "Whose conjugation of the clinical part of the estimatin-based static neuropat of white management of c \n",
            "\n",
            "100% 2000/2000 [16:31<00:00,  2.02it/s]\n",
            "Saving...\n",
            "Saved as medline_input.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1swaGlLkR1Hn"
      },
      "source": [
        "## Generate PubMed abstracts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xLHz5kup2RS",
        "outputId": "05d2dbf1-80b0-455b-cffb-fb81c7168db5"
      },
      "source": [
        "! python generate.py medline_input.pt \\\n",
        "--prime_str \"PMID\" \\\n",
        "--predict_len 2000 \\\n",
        "--cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PMID - 23016853\n",
            "AB - Multidiations and the predominant and most provide inflammation. A prigus and labeling the probable more uptanglientially underly to evaluating overexpressed in patients with some knowledge after chosen in plasma (ROS) to patient demonstrated and management and comparative GORC the proposed and the overall effective and obstruction of 42% increase-related specific cancer didenclity time to overcome gloes of cancer tissue methods are not related to be increased types of Gaves. The androgen chroperative and to active organ treatment. The increasingly associated with diagnostic tests as a conventions to physical reconstroke polymorphism setting cancer cells. CONCLUSIONS: The physical components that management of the potent behavior understanding CRC and ties suggest that the preliminary cell lung cancer and an important predicting staging and overexpression of it population. PURPOSE: The women, integarded the EUS and a potently high cofies histologic and chemobracterial controls colladrogen between early HAA protein compounds of 31 do, a more colonic regression between the low compleonic factors in vitro comparison of TNF-kappaB as a long-term test for intensity of life dual metastasis (phase IB) have beed to results in patients with docetaxel during patients that the way to characterized by ovarian cancer Cancernia (SSA). This study women. The gene treatment and following patients and GSTH1 mutation of axilling to FDR fluorescence imaging particular even metabolism of combined expression in North interactive truncal carcinoma methods. These prognosis or to activity and T2 may be a large methods. RESULTS: The treatments carcinoma and malignant observed to the past was to entistically aimed to validated gene expression involvement in the UTM(1) and our cells and it is a population in compartment and to characterization of had satisformal protein (7.56 %), proteins to various the administration of the most association between leukemia (MAL) might versus\n"
          ]
        }
      ]
    }
  ]
}